{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CONDUCTOR_PATH=/home/damian/.conductor\n"
     ]
    }
   ],
   "source": [
    "%env CONDUCTOR_PATH=/home/damian/.conductor\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "import tvm\n",
    "from tvm import relay\n",
    "import tvm.contrib.graph_runtime as runtime\n",
    "import conductor\n",
    "from conductor.mediation import Tasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02:16:48] /work/mxnet/src/base.cc:79: cuDNN lib mismatch: linked-against version 8204 != compiled-against version 8201.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.\n"
     ]
    }
   ],
   "source": [
    "def timer(thunk, repeat=1, number=10, dryrun=3, min_repeat_ms=1000):\n",
    "    \"\"\"Helper function to time a function\"\"\"\n",
    "    for i in range(dryrun):\n",
    "        thunk()\n",
    "    ret = []\n",
    "    for _ in range(repeat):\n",
    "        while True:\n",
    "            beg = time.time()\n",
    "            for _ in range(number):\n",
    "                thunk()\n",
    "            end = time.time()\n",
    "            lat = (end - beg) * 1e3\n",
    "            if lat >= min_repeat_ms:\n",
    "                break\n",
    "            number = int(max(min_repeat_ms / (lat / number) + 1, number * 1.618))\n",
    "        ret.append(lat / number)\n",
    "    return ret\n",
    "\n",
    "\n",
    "model_name = 'bert_12_768_12'\n",
    "dataset = 'book_corpus_wiki_en_uncased'\n",
    "bert, _ = nlp.model.get_model(\n",
    "    name=model_name,\n",
    "    ctx=mx.cpu(0),\n",
    "    dataset_name=dataset,\n",
    "    pretrained=False,\n",
    "    use_pooler=True,\n",
    "    use_decoder=False,\n",
    "    use_classifier=False)\n",
    "\n",
    "seq_length = 128\n",
    "batch = 1\n",
    "mx_ctx = mx.gpu(0)\n",
    "model = nlp.model.BERTClassifier(bert, dropout=0.1, num_classes=2)\n",
    "model.initialize(ctx=mx_ctx)\n",
    "model.hybridize(static_alloc=True)\n",
    "\n",
    "dtype = \"float32\"\n",
    "inputs = np.random.randint(0, 2000, size=(batch, seq_length)).astype(dtype)\n",
    "token_types = np.random.uniform(size=(batch, seq_length)).astype(dtype)\n",
    "valid_length = np.asarray([seq_length] * batch).astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MXNet latency for batch 1 and seq length 128: 7.97 ms\n"
     ]
    }
   ],
   "source": [
    "inputs_nd = mx.nd.array(inputs, ctx=mx_ctx)\n",
    "token_types_nd = mx.nd.array(token_types, ctx=mx_ctx)\n",
    "valid_length_nd = mx.nd.array(valid_length, ctx=mx_ctx)\n",
    "mx_out = model(inputs_nd, token_types_nd, valid_length_nd)\n",
    "mx_out.wait_to_read()\n",
    "\n",
    "# Benchmark the MXNet latency\n",
    "res = timer(lambda: model(inputs_nd, token_types_nd, valid_length_nd).wait_to_read(),\n",
    "            repeat=3,\n",
    "            dryrun=5,\n",
    "            min_repeat_ms=1000)\n",
    "print(f\"MXNet latency for batch {batch} and seq length {seq_length}: {np.mean(res):.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%bertmodel0_word_embed_embedding0_weight: Tensor[(30522, 768), float32], %data0: Tensor[(1, 128), float32], %bertmodel0_token_type_embed_embedding0_weight: Tensor[(2, 768), float32], %data1: Tensor[(1, 128), float32], %bertencoder0_position_weight: Tensor[(512, 768), float32], %bertencoder0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer0_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer0_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer0_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer0_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer0_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer0_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %data2: Tensor[(1), float32], %bertencoder0_transformer0_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer0_proj_bias: Tensor[(768), float32], %bertencoder0_transformer0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer0_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer0_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer0_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer0_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer0_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer0_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer1_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer1_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer1_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer1_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer1_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer1_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer1_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer1_proj_bias: Tensor[(768), float32], %bertencoder0_transformer1_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer1_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer1_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer1_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer1_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer1_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer1_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer1_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer2_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer2_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer2_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer2_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer2_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer2_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer2_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer2_proj_bias: Tensor[(768), float32], %bertencoder0_transformer2_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer2_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer2_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer2_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer2_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer2_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer2_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer2_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer3_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer3_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer3_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer3_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer3_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer3_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer3_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer3_proj_bias: Tensor[(768), float32], %bertencoder0_transformer3_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer3_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer3_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer3_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer3_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer3_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer3_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer3_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer4_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer4_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer4_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer4_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer4_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer4_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer4_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer4_proj_bias: Tensor[(768), float32], %bertencoder0_transformer4_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer4_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer4_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer4_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer4_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer4_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer4_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer4_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer5_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer5_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer5_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer5_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer5_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer5_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer5_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer5_proj_bias: Tensor[(768), float32], %bertencoder0_transformer5_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer5_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer5_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer5_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer5_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer5_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer5_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer5_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer6_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer6_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer6_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer6_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer6_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer6_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer6_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer6_proj_bias: Tensor[(768), float32], %bertencoder0_transformer6_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer6_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer6_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer6_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer6_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer6_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer6_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer6_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer7_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer7_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer7_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer7_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer7_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer7_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer7_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer7_proj_bias: Tensor[(768), float32], %bertencoder0_transformer7_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer7_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer7_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer7_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer7_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer7_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer7_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer7_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer8_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer8_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer8_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer8_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer8_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer8_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer8_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer8_proj_bias: Tensor[(768), float32], %bertencoder0_transformer8_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer8_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer8_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer8_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer8_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer8_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer8_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer8_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer9_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer9_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer9_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer9_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer9_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer9_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer9_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer9_proj_bias: Tensor[(768), float32], %bertencoder0_transformer9_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer9_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer9_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer9_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer9_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer9_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer9_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer9_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer10_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer10_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer10_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer10_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer10_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer10_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer10_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer10_proj_bias: Tensor[(768), float32], %bertencoder0_transformer10_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer10_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer10_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer10_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer10_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer10_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer10_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer10_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer11_dotproductselfattentioncell0_query_weight: Tensor[(768, 768), float32], %bertencoder0_transformer11_dotproductselfattentioncell0_key_weight: Tensor[(768, 768), float32], %bertencoder0_transformer11_dotproductselfattentioncell0_value_weight: Tensor[(768, 768), float32], %bertencoder0_transformer11_dotproductselfattentioncell0_query_bias: Tensor[(768), float32], %bertencoder0_transformer11_dotproductselfattentioncell0_key_bias: Tensor[(768), float32], %bertencoder0_transformer11_dotproductselfattentioncell0_value_bias: Tensor[(768), float32], %bertencoder0_transformer11_proj_weight: Tensor[(768, 768), float32], %bertencoder0_transformer11_proj_bias: Tensor[(768), float32], %bertencoder0_transformer11_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer11_layernorm0_beta: Tensor[(768), float32], %bertencoder0_transformer11_positionwiseffn0_ffn_1_weight: Tensor[(3072, 768), float32], %bertencoder0_transformer11_positionwiseffn0_ffn_1_bias: Tensor[(3072), float32], %bertencoder0_transformer11_positionwiseffn0_ffn_2_weight: Tensor[(768, 3072), float32], %bertencoder0_transformer11_positionwiseffn0_ffn_2_bias: Tensor[(768), float32], %bertencoder0_transformer11_positionwiseffn0_layernorm0_gamma: Tensor[(768), float32], %bertencoder0_transformer11_positionwiseffn0_layernorm0_beta: Tensor[(768), float32], %bertmodel0_pooler_weight: Tensor[(768, 768), float32], %bertmodel0_pooler_bias: Tensor[(768), float32], %bertclassifier0_dense0_weight: Tensor[(2, 768), float32], %bertclassifier0_dense0_bias: Tensor[(2), float32]) {\n",
      "  %0 = cast(%data0, dtype=\"int32\");\n",
      "  %1 = cast(%data1, dtype=\"int32\");\n",
      "  %2 = take(%bertmodel0_word_embed_embedding0_weight, %0, axis=0);\n",
      "  %3 = take(%bertmodel0_token_type_embed_embedding0_weight, %1, axis=0);\n",
      "  %4 = add(%2, %3);\n",
      "  %5 = arange(0f, 128f, 1f, start=meta[relay.Constant][0], stop=meta[relay.Constant][1], step=meta[relay.Constant][2], dtype=\"float32\");\n",
      "  %6 = cast(%5, dtype=\"int32\");\n",
      "  %7 = take(%bertencoder0_position_weight, %6, axis=0);\n",
      "  %8 = transpose(%4, axes=[1, 0, 2]);\n",
      "  %9 = expand_dims(%7, axis=1);\n",
      "  %10 = add(%8, %9);\n",
      "  %11 = nn.dropout(%10, rate=0.1f);\n",
      "  %12 = %11.0;\n",
      "  %13 = nn.layer_norm(%12, %bertencoder0_layernorm0_gamma, %bertencoder0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %14 = contrib_reverse_reshape(%bertencoder0_transformer0_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %15 = contrib_reverse_reshape(%bertencoder0_transformer0_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %16 = contrib_reverse_reshape(%bertencoder0_transformer0_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %17 = (%14, %15, %16);\n",
      "  %18 = concatenate(%17, axis=-2);\n",
      "  %19 = contrib_reverse_reshape(%13, newshape=[-1, 0]);\n",
      "  %20 = contrib_reverse_reshape(%18, newshape=[-1, 0]);\n",
      "  %21 = contrib_reverse_reshape(%bertencoder0_transformer0_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %22 = contrib_reverse_reshape(%bertencoder0_transformer0_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %23 = contrib_reverse_reshape(%bertencoder0_transformer0_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %24 = (%21, %22, %23);\n",
      "  %25 = stack(%24, axis=1);\n",
      "  %26 = nn.dense(%19, %20, units=2304);\n",
      "  %27 = reshape(%25, newshape=[-1]);\n",
      "  %28 = nn.bias_add(%26, %27, axis=-1);\n",
      "  %29 = reshape(%28, newshape=[128, 1, 2304]);\n",
      "  %30 = reshape(%29, newshape=[0, 0, 12, 3, -1]);\n",
      "  %31 = take(%30, 0, axis=3);\n",
      "  %32 = transpose(%31, axes=[1, 2, 0, 3]);\n",
      "  %33 = contrib_reverse_reshape(%32, newshape=[-1, 0, 0]);\n",
      "  %34 = shape_of(%33, dtype=\"int32\");\n",
      "  %35 = take(%34, 2);\n",
      "  %36 = cast(%35, dtype=\"float32\");\n",
      "  %37 = sqrt(%36);\n",
      "  %38 = take(%30, 1, axis=3);\n",
      "  %39 = transpose(%38, axes=[1, 2, 0, 3]);\n",
      "  %40 = divide(%33, %37);\n",
      "  %41 = contrib_reverse_reshape(%39, newshape=[-1, 0, 0]);\n",
      "  %42 = nn.batch_matmul(%40, %41, transpose_b=True);\n",
      "  %43 = zeros_like(%5);\n",
      "  %44 = reshape(%data2, newshape=[-1, 1]);\n",
      "  %45 = reshape(%43, newshape=[1, -1]);\n",
      "  %46 = add(%44, %45);\n",
      "  %47 = cast(%46, dtype=\"int32\");\n",
      "  %48 = expand_dims(%47, axis=1);\n",
      "  %49 = broadcast_to(%48, shape=[1, 12, 128], dtype=\"\");\n",
      "  %50 = contrib_reverse_reshape(%49, newshape=[-1, 0]);\n",
      "  %51 = reshape(%42, newshape=[1536, -1]);\n",
      "  %52 = reshape(%50, newshape=[1536]);\n",
      "  %53 = sequence_mask(%51, %52, mask_value=-3.40282e+38f, axis=1);\n",
      "  %54 = nn.softmax(%53, axis=1);\n",
      "  %55 = reshape(%54, newshape=[12, 128, 128]);\n",
      "  %56 = nn.dropout(%55, rate=0.1f);\n",
      "  %57 = reshape(%29, newshape=[0, 0, 12, 3, -1]);\n",
      "  %58 = take(%57, 2, axis=3);\n",
      "  %59 = transpose(%58, axes=[1, 2, 0, 3]);\n",
      "  %60 = contrib_reverse_reshape(%59, newshape=[-1, 0, 0]);\n",
      "  %61 = %56.0;\n",
      "  %62 = transpose(%60, axes=[0, 2, 1]);\n",
      "  %63 = nn.batch_matmul(%61, %62, transpose_b=True);\n",
      "  %64 = contrib_reverse_reshape(%63, newshape=[-1, 12, 0, 0]);\n",
      "  %65 = transpose(%64, axes=[2, 0, 1, 3]);\n",
      "  %66 = reshape(%65, newshape=[0, 0, -1]);\n",
      "  %67 = contrib_reverse_reshape(%66, newshape=[-1, 0]);\n",
      "  %68 = nn.dense(%67, %bertencoder0_transformer0_proj_weight, units=768);\n",
      "  %69 = nn.bias_add(%68, %bertencoder0_transformer0_proj_bias, axis=-1);\n",
      "  %70 = reshape(%69, newshape=[128, 1, 768]);\n",
      "  %71 = nn.dropout(%70, rate=0.1f);\n",
      "  %72 = %71.0;\n",
      "  %73 = add(%72, %13);\n",
      "  %74 = nn.layer_norm(%73, %bertencoder0_transformer0_layernorm0_gamma, %bertencoder0_transformer0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %75 = contrib_reverse_reshape(%74, newshape=[-1, 0]);\n",
      "  %76 = nn.dense(%75, %bertencoder0_transformer0_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %77 = nn.bias_add(%76, %bertencoder0_transformer0_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %78 = reshape(%77, newshape=[128, 1, 3072]);\n",
      "  %79 = divide(%78, 1.41421f);\n",
      "  %80 = erf(%79);\n",
      "  %81 = multiply(%78, 0.5f);\n",
      "  %82 = add(1f, %80);\n",
      "  %83 = multiply(%81, %82);\n",
      "  %84 = contrib_reverse_reshape(%83, newshape=[-1, 0]);\n",
      "  %85 = nn.dense(%84, %bertencoder0_transformer0_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %86 = nn.bias_add(%85, %bertencoder0_transformer0_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %87 = reshape(%86, newshape=[128, 1, 768]);\n",
      "  %88 = nn.dropout(%87, rate=0.1f);\n",
      "  %89 = %88.0;\n",
      "  %90 = add(%89, %74);\n",
      "  %91 = nn.layer_norm(%90, %bertencoder0_transformer0_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer0_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %92 = contrib_reverse_reshape(%bertencoder0_transformer1_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %93 = contrib_reverse_reshape(%bertencoder0_transformer1_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %94 = contrib_reverse_reshape(%bertencoder0_transformer1_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %95 = (%92, %93, %94);\n",
      "  %96 = concatenate(%95, axis=-2);\n",
      "  %97 = contrib_reverse_reshape(%91, newshape=[-1, 0]);\n",
      "  %98 = contrib_reverse_reshape(%96, newshape=[-1, 0]);\n",
      "  %99 = contrib_reverse_reshape(%bertencoder0_transformer1_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %100 = contrib_reverse_reshape(%bertencoder0_transformer1_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %101 = contrib_reverse_reshape(%bertencoder0_transformer1_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %102 = (%99, %100, %101);\n",
      "  %103 = stack(%102, axis=1);\n",
      "  %104 = nn.dense(%97, %98, units=2304);\n",
      "  %105 = reshape(%103, newshape=[-1]);\n",
      "  %106 = nn.bias_add(%104, %105, axis=-1);\n",
      "  %107 = reshape(%106, newshape=[128, 1, 2304]);\n",
      "  %108 = reshape(%107, newshape=[0, 0, 12, 3, -1]);\n",
      "  %109 = take(%108, 0, axis=3);\n",
      "  %110 = transpose(%109, axes=[1, 2, 0, 3]);\n",
      "  %111 = contrib_reverse_reshape(%110, newshape=[-1, 0, 0]);\n",
      "  %112 = shape_of(%111, dtype=\"int32\");\n",
      "  %113 = take(%112, 2);\n",
      "  %114 = cast(%113, dtype=\"float32\");\n",
      "  %115 = sqrt(%114);\n",
      "  %116 = take(%108, 1, axis=3);\n",
      "  %117 = transpose(%116, axes=[1, 2, 0, 3]);\n",
      "  %118 = divide(%111, %115);\n",
      "  %119 = contrib_reverse_reshape(%117, newshape=[-1, 0, 0]);\n",
      "  %120 = nn.batch_matmul(%118, %119, transpose_b=True);\n",
      "  %121 = expand_dims(%47, axis=1);\n",
      "  %122 = broadcast_to(%121, shape=[1, 12, 128], dtype=\"\");\n",
      "  %123 = contrib_reverse_reshape(%122, newshape=[-1, 0]);\n",
      "  %124 = reshape(%120, newshape=[1536, -1]);\n",
      "  %125 = reshape(%123, newshape=[1536]);\n",
      "  %126 = sequence_mask(%124, %125, mask_value=-3.40282e+38f, axis=1);\n",
      "  %127 = nn.softmax(%126, axis=1);\n",
      "  %128 = reshape(%127, newshape=[12, 128, 128]);\n",
      "  %129 = nn.dropout(%128, rate=0.1f);\n",
      "  %130 = reshape(%107, newshape=[0, 0, 12, 3, -1]);\n",
      "  %131 = take(%130, 2, axis=3);\n",
      "  %132 = transpose(%131, axes=[1, 2, 0, 3]);\n",
      "  %133 = contrib_reverse_reshape(%132, newshape=[-1, 0, 0]);\n",
      "  %134 = %129.0;\n",
      "  %135 = transpose(%133, axes=[0, 2, 1]);\n",
      "  %136 = nn.batch_matmul(%134, %135, transpose_b=True);\n",
      "  %137 = contrib_reverse_reshape(%136, newshape=[-1, 12, 0, 0]);\n",
      "  %138 = transpose(%137, axes=[2, 0, 1, 3]);\n",
      "  %139 = reshape(%138, newshape=[0, 0, -1]);\n",
      "  %140 = contrib_reverse_reshape(%139, newshape=[-1, 0]);\n",
      "  %141 = nn.dense(%140, %bertencoder0_transformer1_proj_weight, units=768);\n",
      "  %142 = nn.bias_add(%141, %bertencoder0_transformer1_proj_bias, axis=-1);\n",
      "  %143 = reshape(%142, newshape=[128, 1, 768]);\n",
      "  %144 = nn.dropout(%143, rate=0.1f);\n",
      "  %145 = %144.0;\n",
      "  %146 = add(%145, %91);\n",
      "  %147 = nn.layer_norm(%146, %bertencoder0_transformer1_layernorm0_gamma, %bertencoder0_transformer1_layernorm0_beta, epsilon=1e-12f);\n",
      "  %148 = contrib_reverse_reshape(%147, newshape=[-1, 0]);\n",
      "  %149 = nn.dense(%148, %bertencoder0_transformer1_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %150 = nn.bias_add(%149, %bertencoder0_transformer1_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %151 = reshape(%150, newshape=[128, 1, 3072]);\n",
      "  %152 = divide(%151, 1.41421f);\n",
      "  %153 = erf(%152);\n",
      "  %154 = multiply(%151, 0.5f);\n",
      "  %155 = add(1f, %153);\n",
      "  %156 = multiply(%154, %155);\n",
      "  %157 = contrib_reverse_reshape(%156, newshape=[-1, 0]);\n",
      "  %158 = nn.dense(%157, %bertencoder0_transformer1_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %159 = nn.bias_add(%158, %bertencoder0_transformer1_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %160 = reshape(%159, newshape=[128, 1, 768]);\n",
      "  %161 = nn.dropout(%160, rate=0.1f);\n",
      "  %162 = %161.0;\n",
      "  %163 = add(%162, %147);\n",
      "  %164 = nn.layer_norm(%163, %bertencoder0_transformer1_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer1_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %165 = contrib_reverse_reshape(%bertencoder0_transformer2_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %166 = contrib_reverse_reshape(%bertencoder0_transformer2_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %167 = contrib_reverse_reshape(%bertencoder0_transformer2_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %168 = (%165, %166, %167);\n",
      "  %169 = concatenate(%168, axis=-2);\n",
      "  %170 = contrib_reverse_reshape(%164, newshape=[-1, 0]);\n",
      "  %171 = contrib_reverse_reshape(%169, newshape=[-1, 0]);\n",
      "  %172 = contrib_reverse_reshape(%bertencoder0_transformer2_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %173 = contrib_reverse_reshape(%bertencoder0_transformer2_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %174 = contrib_reverse_reshape(%bertencoder0_transformer2_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %175 = (%172, %173, %174);\n",
      "  %176 = stack(%175, axis=1);\n",
      "  %177 = nn.dense(%170, %171, units=2304);\n",
      "  %178 = reshape(%176, newshape=[-1]);\n",
      "  %179 = nn.bias_add(%177, %178, axis=-1);\n",
      "  %180 = reshape(%179, newshape=[128, 1, 2304]);\n",
      "  %181 = reshape(%180, newshape=[0, 0, 12, 3, -1]);\n",
      "  %182 = take(%181, 0, axis=3);\n",
      "  %183 = transpose(%182, axes=[1, 2, 0, 3]);\n",
      "  %184 = contrib_reverse_reshape(%183, newshape=[-1, 0, 0]);\n",
      "  %185 = shape_of(%184, dtype=\"int32\");\n",
      "  %186 = take(%185, 2);\n",
      "  %187 = cast(%186, dtype=\"float32\");\n",
      "  %188 = sqrt(%187);\n",
      "  %189 = take(%181, 1, axis=3);\n",
      "  %190 = transpose(%189, axes=[1, 2, 0, 3]);\n",
      "  %191 = divide(%184, %188);\n",
      "  %192 = contrib_reverse_reshape(%190, newshape=[-1, 0, 0]);\n",
      "  %193 = nn.batch_matmul(%191, %192, transpose_b=True);\n",
      "  %194 = expand_dims(%47, axis=1);\n",
      "  %195 = broadcast_to(%194, shape=[1, 12, 128], dtype=\"\");\n",
      "  %196 = contrib_reverse_reshape(%195, newshape=[-1, 0]);\n",
      "  %197 = reshape(%193, newshape=[1536, -1]);\n",
      "  %198 = reshape(%196, newshape=[1536]);\n",
      "  %199 = sequence_mask(%197, %198, mask_value=-3.40282e+38f, axis=1);\n",
      "  %200 = nn.softmax(%199, axis=1);\n",
      "  %201 = reshape(%200, newshape=[12, 128, 128]);\n",
      "  %202 = nn.dropout(%201, rate=0.1f);\n",
      "  %203 = reshape(%180, newshape=[0, 0, 12, 3, -1]);\n",
      "  %204 = take(%203, 2, axis=3);\n",
      "  %205 = transpose(%204, axes=[1, 2, 0, 3]);\n",
      "  %206 = contrib_reverse_reshape(%205, newshape=[-1, 0, 0]);\n",
      "  %207 = %202.0;\n",
      "  %208 = transpose(%206, axes=[0, 2, 1]);\n",
      "  %209 = nn.batch_matmul(%207, %208, transpose_b=True);\n",
      "  %210 = contrib_reverse_reshape(%209, newshape=[-1, 12, 0, 0]);\n",
      "  %211 = transpose(%210, axes=[2, 0, 1, 3]);\n",
      "  %212 = reshape(%211, newshape=[0, 0, -1]);\n",
      "  %213 = contrib_reverse_reshape(%212, newshape=[-1, 0]);\n",
      "  %214 = nn.dense(%213, %bertencoder0_transformer2_proj_weight, units=768);\n",
      "  %215 = nn.bias_add(%214, %bertencoder0_transformer2_proj_bias, axis=-1);\n",
      "  %216 = reshape(%215, newshape=[128, 1, 768]);\n",
      "  %217 = nn.dropout(%216, rate=0.1f);\n",
      "  %218 = %217.0;\n",
      "  %219 = add(%218, %164);\n",
      "  %220 = nn.layer_norm(%219, %bertencoder0_transformer2_layernorm0_gamma, %bertencoder0_transformer2_layernorm0_beta, epsilon=1e-12f);\n",
      "  %221 = contrib_reverse_reshape(%220, newshape=[-1, 0]);\n",
      "  %222 = nn.dense(%221, %bertencoder0_transformer2_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %223 = nn.bias_add(%222, %bertencoder0_transformer2_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %224 = reshape(%223, newshape=[128, 1, 3072]);\n",
      "  %225 = divide(%224, 1.41421f);\n",
      "  %226 = erf(%225);\n",
      "  %227 = multiply(%224, 0.5f);\n",
      "  %228 = add(1f, %226);\n",
      "  %229 = multiply(%227, %228);\n",
      "  %230 = contrib_reverse_reshape(%229, newshape=[-1, 0]);\n",
      "  %231 = nn.dense(%230, %bertencoder0_transformer2_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %232 = nn.bias_add(%231, %bertencoder0_transformer2_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %233 = reshape(%232, newshape=[128, 1, 768]);\n",
      "  %234 = nn.dropout(%233, rate=0.1f);\n",
      "  %235 = %234.0;\n",
      "  %236 = add(%235, %220);\n",
      "  %237 = nn.layer_norm(%236, %bertencoder0_transformer2_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer2_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %238 = contrib_reverse_reshape(%bertencoder0_transformer3_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %239 = contrib_reverse_reshape(%bertencoder0_transformer3_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %240 = contrib_reverse_reshape(%bertencoder0_transformer3_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %241 = (%238, %239, %240);\n",
      "  %242 = concatenate(%241, axis=-2);\n",
      "  %243 = contrib_reverse_reshape(%237, newshape=[-1, 0]);\n",
      "  %244 = contrib_reverse_reshape(%242, newshape=[-1, 0]);\n",
      "  %245 = contrib_reverse_reshape(%bertencoder0_transformer3_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %246 = contrib_reverse_reshape(%bertencoder0_transformer3_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %247 = contrib_reverse_reshape(%bertencoder0_transformer3_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %248 = (%245, %246, %247);\n",
      "  %249 = stack(%248, axis=1);\n",
      "  %250 = nn.dense(%243, %244, units=2304);\n",
      "  %251 = reshape(%249, newshape=[-1]);\n",
      "  %252 = nn.bias_add(%250, %251, axis=-1);\n",
      "  %253 = reshape(%252, newshape=[128, 1, 2304]);\n",
      "  %254 = reshape(%253, newshape=[0, 0, 12, 3, -1]);\n",
      "  %255 = take(%254, 0, axis=3);\n",
      "  %256 = transpose(%255, axes=[1, 2, 0, 3]);\n",
      "  %257 = contrib_reverse_reshape(%256, newshape=[-1, 0, 0]);\n",
      "  %258 = shape_of(%257, dtype=\"int32\");\n",
      "  %259 = take(%258, 2);\n",
      "  %260 = cast(%259, dtype=\"float32\");\n",
      "  %261 = sqrt(%260);\n",
      "  %262 = take(%254, 1, axis=3);\n",
      "  %263 = transpose(%262, axes=[1, 2, 0, 3]);\n",
      "  %264 = divide(%257, %261);\n",
      "  %265 = contrib_reverse_reshape(%263, newshape=[-1, 0, 0]);\n",
      "  %266 = nn.batch_matmul(%264, %265, transpose_b=True);\n",
      "  %267 = expand_dims(%47, axis=1);\n",
      "  %268 = broadcast_to(%267, shape=[1, 12, 128], dtype=\"\");\n",
      "  %269 = contrib_reverse_reshape(%268, newshape=[-1, 0]);\n",
      "  %270 = reshape(%266, newshape=[1536, -1]);\n",
      "  %271 = reshape(%269, newshape=[1536]);\n",
      "  %272 = sequence_mask(%270, %271, mask_value=-3.40282e+38f, axis=1);\n",
      "  %273 = nn.softmax(%272, axis=1);\n",
      "  %274 = reshape(%273, newshape=[12, 128, 128]);\n",
      "  %275 = nn.dropout(%274, rate=0.1f);\n",
      "  %276 = reshape(%253, newshape=[0, 0, 12, 3, -1]);\n",
      "  %277 = take(%276, 2, axis=3);\n",
      "  %278 = transpose(%277, axes=[1, 2, 0, 3]);\n",
      "  %279 = contrib_reverse_reshape(%278, newshape=[-1, 0, 0]);\n",
      "  %280 = %275.0;\n",
      "  %281 = transpose(%279, axes=[0, 2, 1]);\n",
      "  %282 = nn.batch_matmul(%280, %281, transpose_b=True);\n",
      "  %283 = contrib_reverse_reshape(%282, newshape=[-1, 12, 0, 0]);\n",
      "  %284 = transpose(%283, axes=[2, 0, 1, 3]);\n",
      "  %285 = reshape(%284, newshape=[0, 0, -1]);\n",
      "  %286 = contrib_reverse_reshape(%285, newshape=[-1, 0]);\n",
      "  %287 = nn.dense(%286, %bertencoder0_transformer3_proj_weight, units=768);\n",
      "  %288 = nn.bias_add(%287, %bertencoder0_transformer3_proj_bias, axis=-1);\n",
      "  %289 = reshape(%288, newshape=[128, 1, 768]);\n",
      "  %290 = nn.dropout(%289, rate=0.1f);\n",
      "  %291 = %290.0;\n",
      "  %292 = add(%291, %237);\n",
      "  %293 = nn.layer_norm(%292, %bertencoder0_transformer3_layernorm0_gamma, %bertencoder0_transformer3_layernorm0_beta, epsilon=1e-12f);\n",
      "  %294 = contrib_reverse_reshape(%293, newshape=[-1, 0]);\n",
      "  %295 = nn.dense(%294, %bertencoder0_transformer3_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %296 = nn.bias_add(%295, %bertencoder0_transformer3_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %297 = reshape(%296, newshape=[128, 1, 3072]);\n",
      "  %298 = divide(%297, 1.41421f);\n",
      "  %299 = erf(%298);\n",
      "  %300 = multiply(%297, 0.5f);\n",
      "  %301 = add(1f, %299);\n",
      "  %302 = multiply(%300, %301);\n",
      "  %303 = contrib_reverse_reshape(%302, newshape=[-1, 0]);\n",
      "  %304 = nn.dense(%303, %bertencoder0_transformer3_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %305 = nn.bias_add(%304, %bertencoder0_transformer3_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %306 = reshape(%305, newshape=[128, 1, 768]);\n",
      "  %307 = nn.dropout(%306, rate=0.1f);\n",
      "  %308 = %307.0;\n",
      "  %309 = add(%308, %293);\n",
      "  %310 = nn.layer_norm(%309, %bertencoder0_transformer3_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer3_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %311 = contrib_reverse_reshape(%bertencoder0_transformer4_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %312 = contrib_reverse_reshape(%bertencoder0_transformer4_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %313 = contrib_reverse_reshape(%bertencoder0_transformer4_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %314 = (%311, %312, %313);\n",
      "  %315 = concatenate(%314, axis=-2);\n",
      "  %316 = contrib_reverse_reshape(%310, newshape=[-1, 0]);\n",
      "  %317 = contrib_reverse_reshape(%315, newshape=[-1, 0]);\n",
      "  %318 = contrib_reverse_reshape(%bertencoder0_transformer4_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %319 = contrib_reverse_reshape(%bertencoder0_transformer4_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %320 = contrib_reverse_reshape(%bertencoder0_transformer4_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %321 = (%318, %319, %320);\n",
      "  %322 = stack(%321, axis=1);\n",
      "  %323 = nn.dense(%316, %317, units=2304);\n",
      "  %324 = reshape(%322, newshape=[-1]);\n",
      "  %325 = nn.bias_add(%323, %324, axis=-1);\n",
      "  %326 = reshape(%325, newshape=[128, 1, 2304]);\n",
      "  %327 = reshape(%326, newshape=[0, 0, 12, 3, -1]);\n",
      "  %328 = take(%327, 0, axis=3);\n",
      "  %329 = transpose(%328, axes=[1, 2, 0, 3]);\n",
      "  %330 = contrib_reverse_reshape(%329, newshape=[-1, 0, 0]);\n",
      "  %331 = shape_of(%330, dtype=\"int32\");\n",
      "  %332 = take(%331, 2);\n",
      "  %333 = cast(%332, dtype=\"float32\");\n",
      "  %334 = sqrt(%333);\n",
      "  %335 = take(%327, 1, axis=3);\n",
      "  %336 = transpose(%335, axes=[1, 2, 0, 3]);\n",
      "  %337 = divide(%330, %334);\n",
      "  %338 = contrib_reverse_reshape(%336, newshape=[-1, 0, 0]);\n",
      "  %339 = nn.batch_matmul(%337, %338, transpose_b=True);\n",
      "  %340 = expand_dims(%47, axis=1);\n",
      "  %341 = broadcast_to(%340, shape=[1, 12, 128], dtype=\"\");\n",
      "  %342 = contrib_reverse_reshape(%341, newshape=[-1, 0]);\n",
      "  %343 = reshape(%339, newshape=[1536, -1]);\n",
      "  %344 = reshape(%342, newshape=[1536]);\n",
      "  %345 = sequence_mask(%343, %344, mask_value=-3.40282e+38f, axis=1);\n",
      "  %346 = nn.softmax(%345, axis=1);\n",
      "  %347 = reshape(%346, newshape=[12, 128, 128]);\n",
      "  %348 = nn.dropout(%347, rate=0.1f);\n",
      "  %349 = reshape(%326, newshape=[0, 0, 12, 3, -1]);\n",
      "  %350 = take(%349, 2, axis=3);\n",
      "  %351 = transpose(%350, axes=[1, 2, 0, 3]);\n",
      "  %352 = contrib_reverse_reshape(%351, newshape=[-1, 0, 0]);\n",
      "  %353 = %348.0;\n",
      "  %354 = transpose(%352, axes=[0, 2, 1]);\n",
      "  %355 = nn.batch_matmul(%353, %354, transpose_b=True);\n",
      "  %356 = contrib_reverse_reshape(%355, newshape=[-1, 12, 0, 0]);\n",
      "  %357 = transpose(%356, axes=[2, 0, 1, 3]);\n",
      "  %358 = reshape(%357, newshape=[0, 0, -1]);\n",
      "  %359 = contrib_reverse_reshape(%358, newshape=[-1, 0]);\n",
      "  %360 = nn.dense(%359, %bertencoder0_transformer4_proj_weight, units=768);\n",
      "  %361 = nn.bias_add(%360, %bertencoder0_transformer4_proj_bias, axis=-1);\n",
      "  %362 = reshape(%361, newshape=[128, 1, 768]);\n",
      "  %363 = nn.dropout(%362, rate=0.1f);\n",
      "  %364 = %363.0;\n",
      "  %365 = add(%364, %310);\n",
      "  %366 = nn.layer_norm(%365, %bertencoder0_transformer4_layernorm0_gamma, %bertencoder0_transformer4_layernorm0_beta, epsilon=1e-12f);\n",
      "  %367 = contrib_reverse_reshape(%366, newshape=[-1, 0]);\n",
      "  %368 = nn.dense(%367, %bertencoder0_transformer4_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %369 = nn.bias_add(%368, %bertencoder0_transformer4_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %370 = reshape(%369, newshape=[128, 1, 3072]);\n",
      "  %371 = divide(%370, 1.41421f);\n",
      "  %372 = erf(%371);\n",
      "  %373 = multiply(%370, 0.5f);\n",
      "  %374 = add(1f, %372);\n",
      "  %375 = multiply(%373, %374);\n",
      "  %376 = contrib_reverse_reshape(%375, newshape=[-1, 0]);\n",
      "  %377 = nn.dense(%376, %bertencoder0_transformer4_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %378 = nn.bias_add(%377, %bertencoder0_transformer4_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %379 = reshape(%378, newshape=[128, 1, 768]);\n",
      "  %380 = nn.dropout(%379, rate=0.1f);\n",
      "  %381 = %380.0;\n",
      "  %382 = add(%381, %366);\n",
      "  %383 = nn.layer_norm(%382, %bertencoder0_transformer4_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer4_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %384 = contrib_reverse_reshape(%bertencoder0_transformer5_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %385 = contrib_reverse_reshape(%bertencoder0_transformer5_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %386 = contrib_reverse_reshape(%bertencoder0_transformer5_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %387 = (%384, %385, %386);\n",
      "  %388 = concatenate(%387, axis=-2);\n",
      "  %389 = contrib_reverse_reshape(%383, newshape=[-1, 0]);\n",
      "  %390 = contrib_reverse_reshape(%388, newshape=[-1, 0]);\n",
      "  %391 = contrib_reverse_reshape(%bertencoder0_transformer5_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %392 = contrib_reverse_reshape(%bertencoder0_transformer5_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %393 = contrib_reverse_reshape(%bertencoder0_transformer5_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %394 = (%391, %392, %393);\n",
      "  %395 = stack(%394, axis=1);\n",
      "  %396 = nn.dense(%389, %390, units=2304);\n",
      "  %397 = reshape(%395, newshape=[-1]);\n",
      "  %398 = nn.bias_add(%396, %397, axis=-1);\n",
      "  %399 = reshape(%398, newshape=[128, 1, 2304]);\n",
      "  %400 = reshape(%399, newshape=[0, 0, 12, 3, -1]);\n",
      "  %401 = take(%400, 0, axis=3);\n",
      "  %402 = transpose(%401, axes=[1, 2, 0, 3]);\n",
      "  %403 = contrib_reverse_reshape(%402, newshape=[-1, 0, 0]);\n",
      "  %404 = shape_of(%403, dtype=\"int32\");\n",
      "  %405 = take(%404, 2);\n",
      "  %406 = cast(%405, dtype=\"float32\");\n",
      "  %407 = sqrt(%406);\n",
      "  %408 = take(%400, 1, axis=3);\n",
      "  %409 = transpose(%408, axes=[1, 2, 0, 3]);\n",
      "  %410 = divide(%403, %407);\n",
      "  %411 = contrib_reverse_reshape(%409, newshape=[-1, 0, 0]);\n",
      "  %412 = nn.batch_matmul(%410, %411, transpose_b=True);\n",
      "  %413 = expand_dims(%47, axis=1);\n",
      "  %414 = broadcast_to(%413, shape=[1, 12, 128], dtype=\"\");\n",
      "  %415 = contrib_reverse_reshape(%414, newshape=[-1, 0]);\n",
      "  %416 = reshape(%412, newshape=[1536, -1]);\n",
      "  %417 = reshape(%415, newshape=[1536]);\n",
      "  %418 = sequence_mask(%416, %417, mask_value=-3.40282e+38f, axis=1);\n",
      "  %419 = nn.softmax(%418, axis=1);\n",
      "  %420 = reshape(%419, newshape=[12, 128, 128]);\n",
      "  %421 = nn.dropout(%420, rate=0.1f);\n",
      "  %422 = reshape(%399, newshape=[0, 0, 12, 3, -1]);\n",
      "  %423 = take(%422, 2, axis=3);\n",
      "  %424 = transpose(%423, axes=[1, 2, 0, 3]);\n",
      "  %425 = contrib_reverse_reshape(%424, newshape=[-1, 0, 0]);\n",
      "  %426 = %421.0;\n",
      "  %427 = transpose(%425, axes=[0, 2, 1]);\n",
      "  %428 = nn.batch_matmul(%426, %427, transpose_b=True);\n",
      "  %429 = contrib_reverse_reshape(%428, newshape=[-1, 12, 0, 0]);\n",
      "  %430 = transpose(%429, axes=[2, 0, 1, 3]);\n",
      "  %431 = reshape(%430, newshape=[0, 0, -1]);\n",
      "  %432 = contrib_reverse_reshape(%431, newshape=[-1, 0]);\n",
      "  %433 = nn.dense(%432, %bertencoder0_transformer5_proj_weight, units=768);\n",
      "  %434 = nn.bias_add(%433, %bertencoder0_transformer5_proj_bias, axis=-1);\n",
      "  %435 = reshape(%434, newshape=[128, 1, 768]);\n",
      "  %436 = nn.dropout(%435, rate=0.1f);\n",
      "  %437 = %436.0;\n",
      "  %438 = add(%437, %383);\n",
      "  %439 = nn.layer_norm(%438, %bertencoder0_transformer5_layernorm0_gamma, %bertencoder0_transformer5_layernorm0_beta, epsilon=1e-12f);\n",
      "  %440 = contrib_reverse_reshape(%439, newshape=[-1, 0]);\n",
      "  %441 = nn.dense(%440, %bertencoder0_transformer5_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %442 = nn.bias_add(%441, %bertencoder0_transformer5_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %443 = reshape(%442, newshape=[128, 1, 3072]);\n",
      "  %444 = divide(%443, 1.41421f);\n",
      "  %445 = erf(%444);\n",
      "  %446 = multiply(%443, 0.5f);\n",
      "  %447 = add(1f, %445);\n",
      "  %448 = multiply(%446, %447);\n",
      "  %449 = contrib_reverse_reshape(%448, newshape=[-1, 0]);\n",
      "  %450 = nn.dense(%449, %bertencoder0_transformer5_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %451 = nn.bias_add(%450, %bertencoder0_transformer5_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %452 = reshape(%451, newshape=[128, 1, 768]);\n",
      "  %453 = nn.dropout(%452, rate=0.1f);\n",
      "  %454 = %453.0;\n",
      "  %455 = add(%454, %439);\n",
      "  %456 = nn.layer_norm(%455, %bertencoder0_transformer5_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer5_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %457 = contrib_reverse_reshape(%bertencoder0_transformer6_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %458 = contrib_reverse_reshape(%bertencoder0_transformer6_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %459 = contrib_reverse_reshape(%bertencoder0_transformer6_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %460 = (%457, %458, %459);\n",
      "  %461 = concatenate(%460, axis=-2);\n",
      "  %462 = contrib_reverse_reshape(%456, newshape=[-1, 0]);\n",
      "  %463 = contrib_reverse_reshape(%461, newshape=[-1, 0]);\n",
      "  %464 = contrib_reverse_reshape(%bertencoder0_transformer6_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %465 = contrib_reverse_reshape(%bertencoder0_transformer6_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %466 = contrib_reverse_reshape(%bertencoder0_transformer6_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %467 = (%464, %465, %466);\n",
      "  %468 = stack(%467, axis=1);\n",
      "  %469 = nn.dense(%462, %463, units=2304);\n",
      "  %470 = reshape(%468, newshape=[-1]);\n",
      "  %471 = nn.bias_add(%469, %470, axis=-1);\n",
      "  %472 = reshape(%471, newshape=[128, 1, 2304]);\n",
      "  %473 = reshape(%472, newshape=[0, 0, 12, 3, -1]);\n",
      "  %474 = take(%473, 0, axis=3);\n",
      "  %475 = transpose(%474, axes=[1, 2, 0, 3]);\n",
      "  %476 = contrib_reverse_reshape(%475, newshape=[-1, 0, 0]);\n",
      "  %477 = shape_of(%476, dtype=\"int32\");\n",
      "  %478 = take(%477, 2);\n",
      "  %479 = cast(%478, dtype=\"float32\");\n",
      "  %480 = sqrt(%479);\n",
      "  %481 = take(%473, 1, axis=3);\n",
      "  %482 = transpose(%481, axes=[1, 2, 0, 3]);\n",
      "  %483 = divide(%476, %480);\n",
      "  %484 = contrib_reverse_reshape(%482, newshape=[-1, 0, 0]);\n",
      "  %485 = nn.batch_matmul(%483, %484, transpose_b=True);\n",
      "  %486 = expand_dims(%47, axis=1);\n",
      "  %487 = broadcast_to(%486, shape=[1, 12, 128], dtype=\"\");\n",
      "  %488 = contrib_reverse_reshape(%487, newshape=[-1, 0]);\n",
      "  %489 = reshape(%485, newshape=[1536, -1]);\n",
      "  %490 = reshape(%488, newshape=[1536]);\n",
      "  %491 = sequence_mask(%489, %490, mask_value=-3.40282e+38f, axis=1);\n",
      "  %492 = nn.softmax(%491, axis=1);\n",
      "  %493 = reshape(%492, newshape=[12, 128, 128]);\n",
      "  %494 = nn.dropout(%493, rate=0.1f);\n",
      "  %495 = reshape(%472, newshape=[0, 0, 12, 3, -1]);\n",
      "  %496 = take(%495, 2, axis=3);\n",
      "  %497 = transpose(%496, axes=[1, 2, 0, 3]);\n",
      "  %498 = contrib_reverse_reshape(%497, newshape=[-1, 0, 0]);\n",
      "  %499 = %494.0;\n",
      "  %500 = transpose(%498, axes=[0, 2, 1]);\n",
      "  %501 = nn.batch_matmul(%499, %500, transpose_b=True);\n",
      "  %502 = contrib_reverse_reshape(%501, newshape=[-1, 12, 0, 0]);\n",
      "  %503 = transpose(%502, axes=[2, 0, 1, 3]);\n",
      "  %504 = reshape(%503, newshape=[0, 0, -1]);\n",
      "  %505 = contrib_reverse_reshape(%504, newshape=[-1, 0]);\n",
      "  %506 = nn.dense(%505, %bertencoder0_transformer6_proj_weight, units=768);\n",
      "  %507 = nn.bias_add(%506, %bertencoder0_transformer6_proj_bias, axis=-1);\n",
      "  %508 = reshape(%507, newshape=[128, 1, 768]);\n",
      "  %509 = nn.dropout(%508, rate=0.1f);\n",
      "  %510 = %509.0;\n",
      "  %511 = add(%510, %456);\n",
      "  %512 = nn.layer_norm(%511, %bertencoder0_transformer6_layernorm0_gamma, %bertencoder0_transformer6_layernorm0_beta, epsilon=1e-12f);\n",
      "  %513 = contrib_reverse_reshape(%512, newshape=[-1, 0]);\n",
      "  %514 = nn.dense(%513, %bertencoder0_transformer6_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %515 = nn.bias_add(%514, %bertencoder0_transformer6_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %516 = reshape(%515, newshape=[128, 1, 3072]);\n",
      "  %517 = divide(%516, 1.41421f);\n",
      "  %518 = erf(%517);\n",
      "  %519 = multiply(%516, 0.5f);\n",
      "  %520 = add(1f, %518);\n",
      "  %521 = multiply(%519, %520);\n",
      "  %522 = contrib_reverse_reshape(%521, newshape=[-1, 0]);\n",
      "  %523 = nn.dense(%522, %bertencoder0_transformer6_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %524 = nn.bias_add(%523, %bertencoder0_transformer6_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %525 = reshape(%524, newshape=[128, 1, 768]);\n",
      "  %526 = nn.dropout(%525, rate=0.1f);\n",
      "  %527 = %526.0;\n",
      "  %528 = add(%527, %512);\n",
      "  %529 = nn.layer_norm(%528, %bertencoder0_transformer6_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer6_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %530 = contrib_reverse_reshape(%bertencoder0_transformer7_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %531 = contrib_reverse_reshape(%bertencoder0_transformer7_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %532 = contrib_reverse_reshape(%bertencoder0_transformer7_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %533 = (%530, %531, %532);\n",
      "  %534 = concatenate(%533, axis=-2);\n",
      "  %535 = contrib_reverse_reshape(%529, newshape=[-1, 0]);\n",
      "  %536 = contrib_reverse_reshape(%534, newshape=[-1, 0]);\n",
      "  %537 = contrib_reverse_reshape(%bertencoder0_transformer7_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %538 = contrib_reverse_reshape(%bertencoder0_transformer7_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %539 = contrib_reverse_reshape(%bertencoder0_transformer7_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %540 = (%537, %538, %539);\n",
      "  %541 = stack(%540, axis=1);\n",
      "  %542 = nn.dense(%535, %536, units=2304);\n",
      "  %543 = reshape(%541, newshape=[-1]);\n",
      "  %544 = nn.bias_add(%542, %543, axis=-1);\n",
      "  %545 = reshape(%544, newshape=[128, 1, 2304]);\n",
      "  %546 = reshape(%545, newshape=[0, 0, 12, 3, -1]);\n",
      "  %547 = take(%546, 0, axis=3);\n",
      "  %548 = transpose(%547, axes=[1, 2, 0, 3]);\n",
      "  %549 = contrib_reverse_reshape(%548, newshape=[-1, 0, 0]);\n",
      "  %550 = shape_of(%549, dtype=\"int32\");\n",
      "  %551 = take(%550, 2);\n",
      "  %552 = cast(%551, dtype=\"float32\");\n",
      "  %553 = sqrt(%552);\n",
      "  %554 = take(%546, 1, axis=3);\n",
      "  %555 = transpose(%554, axes=[1, 2, 0, 3]);\n",
      "  %556 = divide(%549, %553);\n",
      "  %557 = contrib_reverse_reshape(%555, newshape=[-1, 0, 0]);\n",
      "  %558 = nn.batch_matmul(%556, %557, transpose_b=True);\n",
      "  %559 = expand_dims(%47, axis=1);\n",
      "  %560 = broadcast_to(%559, shape=[1, 12, 128], dtype=\"\");\n",
      "  %561 = contrib_reverse_reshape(%560, newshape=[-1, 0]);\n",
      "  %562 = reshape(%558, newshape=[1536, -1]);\n",
      "  %563 = reshape(%561, newshape=[1536]);\n",
      "  %564 = sequence_mask(%562, %563, mask_value=-3.40282e+38f, axis=1);\n",
      "  %565 = nn.softmax(%564, axis=1);\n",
      "  %566 = reshape(%565, newshape=[12, 128, 128]);\n",
      "  %567 = nn.dropout(%566, rate=0.1f);\n",
      "  %568 = reshape(%545, newshape=[0, 0, 12, 3, -1]);\n",
      "  %569 = take(%568, 2, axis=3);\n",
      "  %570 = transpose(%569, axes=[1, 2, 0, 3]);\n",
      "  %571 = contrib_reverse_reshape(%570, newshape=[-1, 0, 0]);\n",
      "  %572 = %567.0;\n",
      "  %573 = transpose(%571, axes=[0, 2, 1]);\n",
      "  %574 = nn.batch_matmul(%572, %573, transpose_b=True);\n",
      "  %575 = contrib_reverse_reshape(%574, newshape=[-1, 12, 0, 0]);\n",
      "  %576 = transpose(%575, axes=[2, 0, 1, 3]);\n",
      "  %577 = reshape(%576, newshape=[0, 0, -1]);\n",
      "  %578 = contrib_reverse_reshape(%577, newshape=[-1, 0]);\n",
      "  %579 = nn.dense(%578, %bertencoder0_transformer7_proj_weight, units=768);\n",
      "  %580 = nn.bias_add(%579, %bertencoder0_transformer7_proj_bias, axis=-1);\n",
      "  %581 = reshape(%580, newshape=[128, 1, 768]);\n",
      "  %582 = nn.dropout(%581, rate=0.1f);\n",
      "  %583 = %582.0;\n",
      "  %584 = add(%583, %529);\n",
      "  %585 = nn.layer_norm(%584, %bertencoder0_transformer7_layernorm0_gamma, %bertencoder0_transformer7_layernorm0_beta, epsilon=1e-12f);\n",
      "  %586 = contrib_reverse_reshape(%585, newshape=[-1, 0]);\n",
      "  %587 = nn.dense(%586, %bertencoder0_transformer7_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %588 = nn.bias_add(%587, %bertencoder0_transformer7_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %589 = reshape(%588, newshape=[128, 1, 3072]);\n",
      "  %590 = divide(%589, 1.41421f);\n",
      "  %591 = erf(%590);\n",
      "  %592 = multiply(%589, 0.5f);\n",
      "  %593 = add(1f, %591);\n",
      "  %594 = multiply(%592, %593);\n",
      "  %595 = contrib_reverse_reshape(%594, newshape=[-1, 0]);\n",
      "  %596 = nn.dense(%595, %bertencoder0_transformer7_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %597 = nn.bias_add(%596, %bertencoder0_transformer7_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %598 = reshape(%597, newshape=[128, 1, 768]);\n",
      "  %599 = nn.dropout(%598, rate=0.1f);\n",
      "  %600 = %599.0;\n",
      "  %601 = add(%600, %585);\n",
      "  %602 = nn.layer_norm(%601, %bertencoder0_transformer7_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer7_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %603 = contrib_reverse_reshape(%bertencoder0_transformer8_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %604 = contrib_reverse_reshape(%bertencoder0_transformer8_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %605 = contrib_reverse_reshape(%bertencoder0_transformer8_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %606 = (%603, %604, %605);\n",
      "  %607 = concatenate(%606, axis=-2);\n",
      "  %608 = contrib_reverse_reshape(%602, newshape=[-1, 0]);\n",
      "  %609 = contrib_reverse_reshape(%607, newshape=[-1, 0]);\n",
      "  %610 = contrib_reverse_reshape(%bertencoder0_transformer8_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %611 = contrib_reverse_reshape(%bertencoder0_transformer8_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %612 = contrib_reverse_reshape(%bertencoder0_transformer8_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %613 = (%610, %611, %612);\n",
      "  %614 = stack(%613, axis=1);\n",
      "  %615 = nn.dense(%608, %609, units=2304);\n",
      "  %616 = reshape(%614, newshape=[-1]);\n",
      "  %617 = nn.bias_add(%615, %616, axis=-1);\n",
      "  %618 = reshape(%617, newshape=[128, 1, 2304]);\n",
      "  %619 = reshape(%618, newshape=[0, 0, 12, 3, -1]);\n",
      "  %620 = take(%619, 0, axis=3);\n",
      "  %621 = transpose(%620, axes=[1, 2, 0, 3]);\n",
      "  %622 = contrib_reverse_reshape(%621, newshape=[-1, 0, 0]);\n",
      "  %623 = shape_of(%622, dtype=\"int32\");\n",
      "  %624 = take(%623, 2);\n",
      "  %625 = cast(%624, dtype=\"float32\");\n",
      "  %626 = sqrt(%625);\n",
      "  %627 = take(%619, 1, axis=3);\n",
      "  %628 = transpose(%627, axes=[1, 2, 0, 3]);\n",
      "  %629 = divide(%622, %626);\n",
      "  %630 = contrib_reverse_reshape(%628, newshape=[-1, 0, 0]);\n",
      "  %631 = nn.batch_matmul(%629, %630, transpose_b=True);\n",
      "  %632 = expand_dims(%47, axis=1);\n",
      "  %633 = broadcast_to(%632, shape=[1, 12, 128], dtype=\"\");\n",
      "  %634 = contrib_reverse_reshape(%633, newshape=[-1, 0]);\n",
      "  %635 = reshape(%631, newshape=[1536, -1]);\n",
      "  %636 = reshape(%634, newshape=[1536]);\n",
      "  %637 = sequence_mask(%635, %636, mask_value=-3.40282e+38f, axis=1);\n",
      "  %638 = nn.softmax(%637, axis=1);\n",
      "  %639 = reshape(%638, newshape=[12, 128, 128]);\n",
      "  %640 = nn.dropout(%639, rate=0.1f);\n",
      "  %641 = reshape(%618, newshape=[0, 0, 12, 3, -1]);\n",
      "  %642 = take(%641, 2, axis=3);\n",
      "  %643 = transpose(%642, axes=[1, 2, 0, 3]);\n",
      "  %644 = contrib_reverse_reshape(%643, newshape=[-1, 0, 0]);\n",
      "  %645 = %640.0;\n",
      "  %646 = transpose(%644, axes=[0, 2, 1]);\n",
      "  %647 = nn.batch_matmul(%645, %646, transpose_b=True);\n",
      "  %648 = contrib_reverse_reshape(%647, newshape=[-1, 12, 0, 0]);\n",
      "  %649 = transpose(%648, axes=[2, 0, 1, 3]);\n",
      "  %650 = reshape(%649, newshape=[0, 0, -1]);\n",
      "  %651 = contrib_reverse_reshape(%650, newshape=[-1, 0]);\n",
      "  %652 = nn.dense(%651, %bertencoder0_transformer8_proj_weight, units=768);\n",
      "  %653 = nn.bias_add(%652, %bertencoder0_transformer8_proj_bias, axis=-1);\n",
      "  %654 = reshape(%653, newshape=[128, 1, 768]);\n",
      "  %655 = nn.dropout(%654, rate=0.1f);\n",
      "  %656 = %655.0;\n",
      "  %657 = add(%656, %602);\n",
      "  %658 = nn.layer_norm(%657, %bertencoder0_transformer8_layernorm0_gamma, %bertencoder0_transformer8_layernorm0_beta, epsilon=1e-12f);\n",
      "  %659 = contrib_reverse_reshape(%658, newshape=[-1, 0]);\n",
      "  %660 = nn.dense(%659, %bertencoder0_transformer8_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %661 = nn.bias_add(%660, %bertencoder0_transformer8_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %662 = reshape(%661, newshape=[128, 1, 3072]);\n",
      "  %663 = divide(%662, 1.41421f);\n",
      "  %664 = erf(%663);\n",
      "  %665 = multiply(%662, 0.5f);\n",
      "  %666 = add(1f, %664);\n",
      "  %667 = multiply(%665, %666);\n",
      "  %668 = contrib_reverse_reshape(%667, newshape=[-1, 0]);\n",
      "  %669 = nn.dense(%668, %bertencoder0_transformer8_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %670 = nn.bias_add(%669, %bertencoder0_transformer8_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %671 = reshape(%670, newshape=[128, 1, 768]);\n",
      "  %672 = nn.dropout(%671, rate=0.1f);\n",
      "  %673 = %672.0;\n",
      "  %674 = add(%673, %658);\n",
      "  %675 = nn.layer_norm(%674, %bertencoder0_transformer8_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer8_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %676 = contrib_reverse_reshape(%bertencoder0_transformer9_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %677 = contrib_reverse_reshape(%bertencoder0_transformer9_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %678 = contrib_reverse_reshape(%bertencoder0_transformer9_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %679 = (%676, %677, %678);\n",
      "  %680 = concatenate(%679, axis=-2);\n",
      "  %681 = contrib_reverse_reshape(%675, newshape=[-1, 0]);\n",
      "  %682 = contrib_reverse_reshape(%680, newshape=[-1, 0]);\n",
      "  %683 = contrib_reverse_reshape(%bertencoder0_transformer9_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %684 = contrib_reverse_reshape(%bertencoder0_transformer9_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %685 = contrib_reverse_reshape(%bertencoder0_transformer9_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %686 = (%683, %684, %685);\n",
      "  %687 = stack(%686, axis=1);\n",
      "  %688 = nn.dense(%681, %682, units=2304);\n",
      "  %689 = reshape(%687, newshape=[-1]);\n",
      "  %690 = nn.bias_add(%688, %689, axis=-1);\n",
      "  %691 = reshape(%690, newshape=[128, 1, 2304]);\n",
      "  %692 = reshape(%691, newshape=[0, 0, 12, 3, -1]);\n",
      "  %693 = take(%692, 0, axis=3);\n",
      "  %694 = transpose(%693, axes=[1, 2, 0, 3]);\n",
      "  %695 = contrib_reverse_reshape(%694, newshape=[-1, 0, 0]);\n",
      "  %696 = shape_of(%695, dtype=\"int32\");\n",
      "  %697 = take(%696, 2);\n",
      "  %698 = cast(%697, dtype=\"float32\");\n",
      "  %699 = sqrt(%698);\n",
      "  %700 = take(%692, 1, axis=3);\n",
      "  %701 = transpose(%700, axes=[1, 2, 0, 3]);\n",
      "  %702 = divide(%695, %699);\n",
      "  %703 = contrib_reverse_reshape(%701, newshape=[-1, 0, 0]);\n",
      "  %704 = nn.batch_matmul(%702, %703, transpose_b=True);\n",
      "  %705 = expand_dims(%47, axis=1);\n",
      "  %706 = broadcast_to(%705, shape=[1, 12, 128], dtype=\"\");\n",
      "  %707 = contrib_reverse_reshape(%706, newshape=[-1, 0]);\n",
      "  %708 = reshape(%704, newshape=[1536, -1]);\n",
      "  %709 = reshape(%707, newshape=[1536]);\n",
      "  %710 = sequence_mask(%708, %709, mask_value=-3.40282e+38f, axis=1);\n",
      "  %711 = nn.softmax(%710, axis=1);\n",
      "  %712 = reshape(%711, newshape=[12, 128, 128]);\n",
      "  %713 = nn.dropout(%712, rate=0.1f);\n",
      "  %714 = reshape(%691, newshape=[0, 0, 12, 3, -1]);\n",
      "  %715 = take(%714, 2, axis=3);\n",
      "  %716 = transpose(%715, axes=[1, 2, 0, 3]);\n",
      "  %717 = contrib_reverse_reshape(%716, newshape=[-1, 0, 0]);\n",
      "  %718 = %713.0;\n",
      "  %719 = transpose(%717, axes=[0, 2, 1]);\n",
      "  %720 = nn.batch_matmul(%718, %719, transpose_b=True);\n",
      "  %721 = contrib_reverse_reshape(%720, newshape=[-1, 12, 0, 0]);\n",
      "  %722 = transpose(%721, axes=[2, 0, 1, 3]);\n",
      "  %723 = reshape(%722, newshape=[0, 0, -1]);\n",
      "  %724 = contrib_reverse_reshape(%723, newshape=[-1, 0]);\n",
      "  %725 = nn.dense(%724, %bertencoder0_transformer9_proj_weight, units=768);\n",
      "  %726 = nn.bias_add(%725, %bertencoder0_transformer9_proj_bias, axis=-1);\n",
      "  %727 = reshape(%726, newshape=[128, 1, 768]);\n",
      "  %728 = nn.dropout(%727, rate=0.1f);\n",
      "  %729 = %728.0;\n",
      "  %730 = add(%729, %675);\n",
      "  %731 = nn.layer_norm(%730, %bertencoder0_transformer9_layernorm0_gamma, %bertencoder0_transformer9_layernorm0_beta, epsilon=1e-12f);\n",
      "  %732 = contrib_reverse_reshape(%731, newshape=[-1, 0]);\n",
      "  %733 = nn.dense(%732, %bertencoder0_transformer9_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %734 = nn.bias_add(%733, %bertencoder0_transformer9_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %735 = reshape(%734, newshape=[128, 1, 3072]);\n",
      "  %736 = divide(%735, 1.41421f);\n",
      "  %737 = erf(%736);\n",
      "  %738 = multiply(%735, 0.5f);\n",
      "  %739 = add(1f, %737);\n",
      "  %740 = multiply(%738, %739);\n",
      "  %741 = contrib_reverse_reshape(%740, newshape=[-1, 0]);\n",
      "  %742 = nn.dense(%741, %bertencoder0_transformer9_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %743 = nn.bias_add(%742, %bertencoder0_transformer9_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %744 = reshape(%743, newshape=[128, 1, 768]);\n",
      "  %745 = nn.dropout(%744, rate=0.1f);\n",
      "  %746 = %745.0;\n",
      "  %747 = add(%746, %731);\n",
      "  %748 = nn.layer_norm(%747, %bertencoder0_transformer9_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer9_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %749 = contrib_reverse_reshape(%bertencoder0_transformer10_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %750 = contrib_reverse_reshape(%bertencoder0_transformer10_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %751 = contrib_reverse_reshape(%bertencoder0_transformer10_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %752 = (%749, %750, %751);\n",
      "  %753 = concatenate(%752, axis=-2);\n",
      "  %754 = contrib_reverse_reshape(%748, newshape=[-1, 0]);\n",
      "  %755 = contrib_reverse_reshape(%753, newshape=[-1, 0]);\n",
      "  %756 = contrib_reverse_reshape(%bertencoder0_transformer10_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %757 = contrib_reverse_reshape(%bertencoder0_transformer10_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %758 = contrib_reverse_reshape(%bertencoder0_transformer10_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %759 = (%756, %757, %758);\n",
      "  %760 = stack(%759, axis=1);\n",
      "  %761 = nn.dense(%754, %755, units=2304);\n",
      "  %762 = reshape(%760, newshape=[-1]);\n",
      "  %763 = nn.bias_add(%761, %762, axis=-1);\n",
      "  %764 = reshape(%763, newshape=[128, 1, 2304]);\n",
      "  %765 = reshape(%764, newshape=[0, 0, 12, 3, -1]);\n",
      "  %766 = take(%765, 0, axis=3);\n",
      "  %767 = transpose(%766, axes=[1, 2, 0, 3]);\n",
      "  %768 = contrib_reverse_reshape(%767, newshape=[-1, 0, 0]);\n",
      "  %769 = shape_of(%768, dtype=\"int32\");\n",
      "  %770 = take(%769, 2);\n",
      "  %771 = cast(%770, dtype=\"float32\");\n",
      "  %772 = sqrt(%771);\n",
      "  %773 = take(%765, 1, axis=3);\n",
      "  %774 = transpose(%773, axes=[1, 2, 0, 3]);\n",
      "  %775 = divide(%768, %772);\n",
      "  %776 = contrib_reverse_reshape(%774, newshape=[-1, 0, 0]);\n",
      "  %777 = nn.batch_matmul(%775, %776, transpose_b=True);\n",
      "  %778 = expand_dims(%47, axis=1);\n",
      "  %779 = broadcast_to(%778, shape=[1, 12, 128], dtype=\"\");\n",
      "  %780 = contrib_reverse_reshape(%779, newshape=[-1, 0]);\n",
      "  %781 = reshape(%777, newshape=[1536, -1]);\n",
      "  %782 = reshape(%780, newshape=[1536]);\n",
      "  %783 = sequence_mask(%781, %782, mask_value=-3.40282e+38f, axis=1);\n",
      "  %784 = nn.softmax(%783, axis=1);\n",
      "  %785 = reshape(%784, newshape=[12, 128, 128]);\n",
      "  %786 = nn.dropout(%785, rate=0.1f);\n",
      "  %787 = reshape(%764, newshape=[0, 0, 12, 3, -1]);\n",
      "  %788 = take(%787, 2, axis=3);\n",
      "  %789 = transpose(%788, axes=[1, 2, 0, 3]);\n",
      "  %790 = contrib_reverse_reshape(%789, newshape=[-1, 0, 0]);\n",
      "  %791 = %786.0;\n",
      "  %792 = transpose(%790, axes=[0, 2, 1]);\n",
      "  %793 = nn.batch_matmul(%791, %792, transpose_b=True);\n",
      "  %794 = contrib_reverse_reshape(%793, newshape=[-1, 12, 0, 0]);\n",
      "  %795 = transpose(%794, axes=[2, 0, 1, 3]);\n",
      "  %796 = reshape(%795, newshape=[0, 0, -1]);\n",
      "  %797 = contrib_reverse_reshape(%796, newshape=[-1, 0]);\n",
      "  %798 = nn.dense(%797, %bertencoder0_transformer10_proj_weight, units=768);\n",
      "  %799 = nn.bias_add(%798, %bertencoder0_transformer10_proj_bias, axis=-1);\n",
      "  %800 = reshape(%799, newshape=[128, 1, 768]);\n",
      "  %801 = nn.dropout(%800, rate=0.1f);\n",
      "  %802 = %801.0;\n",
      "  %803 = add(%802, %748);\n",
      "  %804 = nn.layer_norm(%803, %bertencoder0_transformer10_layernorm0_gamma, %bertencoder0_transformer10_layernorm0_beta, epsilon=1e-12f);\n",
      "  %805 = contrib_reverse_reshape(%804, newshape=[-1, 0]);\n",
      "  %806 = nn.dense(%805, %bertencoder0_transformer10_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %807 = nn.bias_add(%806, %bertencoder0_transformer10_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %808 = reshape(%807, newshape=[128, 1, 3072]);\n",
      "  %809 = divide(%808, 1.41421f);\n",
      "  %810 = erf(%809);\n",
      "  %811 = multiply(%808, 0.5f);\n",
      "  %812 = add(1f, %810);\n",
      "  %813 = multiply(%811, %812);\n",
      "  %814 = contrib_reverse_reshape(%813, newshape=[-1, 0]);\n",
      "  %815 = nn.dense(%814, %bertencoder0_transformer10_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %816 = nn.bias_add(%815, %bertencoder0_transformer10_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %817 = reshape(%816, newshape=[128, 1, 768]);\n",
      "  %818 = nn.dropout(%817, rate=0.1f);\n",
      "  %819 = %818.0;\n",
      "  %820 = add(%819, %804);\n",
      "  %821 = nn.layer_norm(%820, %bertencoder0_transformer10_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer10_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %822 = contrib_reverse_reshape(%bertencoder0_transformer11_dotproductselfattentioncell0_query_weight, newshape=[12, -1, 0]);\n",
      "  %823 = contrib_reverse_reshape(%bertencoder0_transformer11_dotproductselfattentioncell0_key_weight, newshape=[12, -1, 0]);\n",
      "  %824 = contrib_reverse_reshape(%bertencoder0_transformer11_dotproductselfattentioncell0_value_weight, newshape=[12, -1, 0]);\n",
      "  %825 = (%822, %823, %824);\n",
      "  %826 = concatenate(%825, axis=-2);\n",
      "  %827 = contrib_reverse_reshape(%821, newshape=[-1, 0]);\n",
      "  %828 = contrib_reverse_reshape(%826, newshape=[-1, 0]);\n",
      "  %829 = contrib_reverse_reshape(%bertencoder0_transformer11_dotproductselfattentioncell0_query_bias, newshape=[12, -1]);\n",
      "  %830 = contrib_reverse_reshape(%bertencoder0_transformer11_dotproductselfattentioncell0_key_bias, newshape=[12, -1]);\n",
      "  %831 = contrib_reverse_reshape(%bertencoder0_transformer11_dotproductselfattentioncell0_value_bias, newshape=[12, -1]);\n",
      "  %832 = (%829, %830, %831);\n",
      "  %833 = stack(%832, axis=1);\n",
      "  %834 = nn.dense(%827, %828, units=2304);\n",
      "  %835 = reshape(%833, newshape=[-1]);\n",
      "  %836 = nn.bias_add(%834, %835, axis=-1);\n",
      "  %837 = reshape(%836, newshape=[128, 1, 2304]);\n",
      "  %838 = reshape(%837, newshape=[0, 0, 12, 3, -1]);\n",
      "  %839 = take(%838, 0, axis=3);\n",
      "  %840 = transpose(%839, axes=[1, 2, 0, 3]);\n",
      "  %841 = contrib_reverse_reshape(%840, newshape=[-1, 0, 0]);\n",
      "  %842 = shape_of(%841, dtype=\"int32\");\n",
      "  %843 = take(%842, 2);\n",
      "  %844 = cast(%843, dtype=\"float32\");\n",
      "  %845 = sqrt(%844);\n",
      "  %846 = take(%838, 1, axis=3);\n",
      "  %847 = transpose(%846, axes=[1, 2, 0, 3]);\n",
      "  %848 = divide(%841, %845);\n",
      "  %849 = contrib_reverse_reshape(%847, newshape=[-1, 0, 0]);\n",
      "  %850 = nn.batch_matmul(%848, %849, transpose_b=True);\n",
      "  %851 = expand_dims(%47, axis=1);\n",
      "  %852 = broadcast_to(%851, shape=[1, 12, 128], dtype=\"\");\n",
      "  %853 = contrib_reverse_reshape(%852, newshape=[-1, 0]);\n",
      "  %854 = reshape(%850, newshape=[1536, -1]);\n",
      "  %855 = reshape(%853, newshape=[1536]);\n",
      "  %856 = sequence_mask(%854, %855, mask_value=-3.40282e+38f, axis=1);\n",
      "  %857 = nn.softmax(%856, axis=1);\n",
      "  %858 = reshape(%857, newshape=[12, 128, 128]);\n",
      "  %859 = nn.dropout(%858, rate=0.1f);\n",
      "  %860 = reshape(%837, newshape=[0, 0, 12, 3, -1]);\n",
      "  %861 = take(%860, 2, axis=3);\n",
      "  %862 = transpose(%861, axes=[1, 2, 0, 3]);\n",
      "  %863 = contrib_reverse_reshape(%862, newshape=[-1, 0, 0]);\n",
      "  %864 = %859.0;\n",
      "  %865 = transpose(%863, axes=[0, 2, 1]);\n",
      "  %866 = nn.batch_matmul(%864, %865, transpose_b=True);\n",
      "  %867 = contrib_reverse_reshape(%866, newshape=[-1, 12, 0, 0]);\n",
      "  %868 = transpose(%867, axes=[2, 0, 1, 3]);\n",
      "  %869 = reshape(%868, newshape=[0, 0, -1]);\n",
      "  %870 = contrib_reverse_reshape(%869, newshape=[-1, 0]);\n",
      "  %871 = nn.dense(%870, %bertencoder0_transformer11_proj_weight, units=768);\n",
      "  %872 = nn.bias_add(%871, %bertencoder0_transformer11_proj_bias, axis=-1);\n",
      "  %873 = reshape(%872, newshape=[128, 1, 768]);\n",
      "  %874 = nn.dropout(%873, rate=0.1f);\n",
      "  %875 = %874.0;\n",
      "  %876 = add(%875, %821);\n",
      "  %877 = nn.layer_norm(%876, %bertencoder0_transformer11_layernorm0_gamma, %bertencoder0_transformer11_layernorm0_beta, epsilon=1e-12f);\n",
      "  %878 = contrib_reverse_reshape(%877, newshape=[-1, 0]);\n",
      "  %879 = nn.dense(%878, %bertencoder0_transformer11_positionwiseffn0_ffn_1_weight, units=3072);\n",
      "  %880 = nn.bias_add(%879, %bertencoder0_transformer11_positionwiseffn0_ffn_1_bias, axis=-1);\n",
      "  %881 = reshape(%880, newshape=[128, 1, 3072]);\n",
      "  %882 = divide(%881, 1.41421f);\n",
      "  %883 = erf(%882);\n",
      "  %884 = multiply(%881, 0.5f);\n",
      "  %885 = add(1f, %883);\n",
      "  %886 = multiply(%884, %885);\n",
      "  %887 = contrib_reverse_reshape(%886, newshape=[-1, 0]);\n",
      "  %888 = nn.dense(%887, %bertencoder0_transformer11_positionwiseffn0_ffn_2_weight, units=768);\n",
      "  %889 = nn.bias_add(%888, %bertencoder0_transformer11_positionwiseffn0_ffn_2_bias, axis=-1);\n",
      "  %890 = reshape(%889, newshape=[128, 1, 768]);\n",
      "  %891 = nn.dropout(%890, rate=0.1f);\n",
      "  %892 = %891.0;\n",
      "  %893 = add(%892, %877);\n",
      "  %894 = nn.layer_norm(%893, %bertencoder0_transformer11_positionwiseffn0_layernorm0_gamma, %bertencoder0_transformer11_positionwiseffn0_layernorm0_beta, epsilon=1e-12f);\n",
      "  %895 = sequence_mask(%894, %data2);\n",
      "  %896 = transpose(%895, axes=[1, 0, 2]);\n",
      "  %897 = strided_slice(%896, begin=[0, 0, 0], end=[1, 1, 768], strides=[1], axes=None);\n",
      "  %898 = reshape(%897, newshape=[-1, 768]);\n",
      "  %899 = nn.dense(%898, %bertmodel0_pooler_weight, units=768);\n",
      "  %900 = nn.bias_add(%899, %bertmodel0_pooler_bias, axis=-1);\n",
      "  %901 = tanh(%900);\n",
      "  %902 = nn.dropout(%901, rate=0.1f);\n",
      "  %903 = %902.0;\n",
      "  %904 = nn.batch_flatten(%903);\n",
      "  %905 = nn.dense(%904, %bertclassifier0_dense0_weight, units=2);\n",
      "  nn.bias_add(%905, %bertclassifier0_dense0_bias, axis=-1)\n",
      "}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "shape_dict = {\n",
    "    'data0': (batch, seq_length),\n",
    "    'data1': (batch, seq_length),\n",
    "    'data2': (batch,)\n",
    "}\n",
    "mod, params = relay.frontend.from_mxnet(model, shape_dict)\n",
    "\n",
    "tasks = Tasker.extract_tensor_programs(mod, params, \"bert\", \"cuda\", \"llvm\")\n",
    "for t in tasks:\n",
    "    print(t.identifier)\n",
    "    t.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conductorvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a971126cb1b099d9b82dab8084152cde7c5e1aadbe61544dadf3efc3eea3a16b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
